{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proteus21/DATA-SCIENCE-STUDY/blob/main/Computer%20Vision/Tensorflow_Exercises_part_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensorflow - Data pipelines - Fifth Exercise (20 minutes)\n",
        "@author Tomasz Skrzypczyk\n",
        "\n",
        "Solved by Boguslaw Konefal"
      ],
      "metadata": {
        "id": "_rxuWocLPRLR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoIA8z_dPNqT"
      },
      "outputs": [],
      "source": [
        "# do not modify this cell\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "data = load_iris()\n",
        "columns = data.feature_names\n",
        "\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size= 0.1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=0.1)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First attempt to tf.data.Dataset\n",
        "\n",
        "Lets create a dataset - it works sth like pandas Dataframe, but its more functional.\n",
        "\n",
        "\n",
        "Create your dataset by using the tf.data.Dataset.from_tensor_slices function.\n",
        "Pass a tuple - your X and y.\n",
        "\n",
        "Create both training, validation and test datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Next step: shuffle the data using the shuffle method. Warning: it returns the shuffled dataset, so you must assign it back to the original variable. See some examples here:  https://stackoverflow.com/questions/50437234/tensorflow-dataset-shuffle-then-batch-or-batch-then-shuffle\n",
        "Also, remember which datasets you actually want to shuffle, do we need it for validation or test set?\n",
        "\n",
        "Last step: Split your data in batches, its kind of mandatory. Use the batch method, set batch_size to 32.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7buHBGj_TRgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_ds = train_ds.shuffle(9)\n",
        "train_ds = train_ds.batch(32)\n",
        "\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "val_ds = val_ds.batch(15)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "test_ds = test_ds.batch(46)"
      ],
      "metadata": {
        "id": "A4IvWHFpTPBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do not modify this cell\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(3, input_shape=(4,)))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "model.evaluate(train_ds)\n",
        "model.evaluate(val_ds)\n",
        "model.evaluate(test_ds)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r17TV5ZPTfo7",
        "outputId": "d92d20cb-f270-41e1-c23f-9ef9c4780544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 10.5308\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4726\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.005592346191406"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second approach - using a generator\n",
        "\n",
        "\n",
        "This method is slightly more difficult, but more efficient and gives you more options.\n",
        "\n",
        "\n",
        "Write a generator function that yields a tuple of data - single x and y\n",
        "\n",
        "```\n",
        "def my_data_generator(X, y):\n",
        "\n",
        "\n",
        "    # some code, very often in a for loop\n",
        "    for ...\n",
        "        # some code here\n",
        "\n",
        "        yield sample, label\n",
        "\n",
        "```\n",
        "\n",
        "Create your Dataset by using your data generator (https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_generator)\n",
        "\n",
        "```\n",
        "ds = = tf.data.Dataset.from_generator(\n",
        "     my_data_generator,\n",
        "     output_signature=(\n",
        "         tf.TensorSpec(shape=(4,), dtype=tf.int32),\n",
        "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
        "\n",
        "\n",
        "```\n",
        "You will be asked to define the output_signature parameter,\n",
        "try this approach \n",
        "\n",
        "`output_signature=(\n",
        "         tf.TensorSpec(shape=(shape of a single sample), dtype=datatype),\n",
        "         tf.TensorSpec(shape=(shape of a single label), dtype=datatype)))`\n",
        "\n",
        "Our samples are expressed with floats, remember iris data?, and the labels - its a single integer.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "apzi7ODJa1QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create your generator function and then create your 3 datasets again using the generator, \n",
        "# one generator for 3 datasets, remember the shuffling and batching operations!!\n",
        "\n",
        "\n",
        "\n",
        "def my_data_generator(X,Y):\n",
        "\n",
        "  def my_data_generator_tr():\n",
        "      for x,y in zip(X, Y):\n",
        "        yield x, (y,)\n",
        "\n",
        "  return my_data_generator_tr\n",
        "\n",
        "\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(\n",
        "     my_data_generator(X_train, y_train),\n",
        "     output_signature=(\n",
        "         tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
        "train_ds = train_ds.shuffle(9)\n",
        "train_ds = train_ds.batch(32)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_generator(\n",
        "     my_data_generator(X_val, y_val),\n",
        "     output_signature=(\n",
        "         tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
        "val_ds = val_ds.batch(15)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(\n",
        "     my_data_generator(X_test, y_test),\n",
        "     output_signature=(\n",
        "         tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
        "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
        "test_ds = test_ds.batch(46)\n"
      ],
      "metadata": {
        "id": "spG5hRTWT42J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if this cell compiles to see if you have defined your datasets correctly\n",
        "\n",
        "\n",
        "model.evaluate(train_ds)\n",
        "model.evaluate(val_ds)\n",
        "model.evaluate(test_ds)"
      ],
      "metadata": {
        "id": "bzZZEun8dEuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c930bc6-3553-4cb9-dac8-bb82ba1aa80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 19ms/step - loss: 10.5308\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 10.4726\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 8.0056\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.005592346191406"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tZ1XfZVjFHG4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}