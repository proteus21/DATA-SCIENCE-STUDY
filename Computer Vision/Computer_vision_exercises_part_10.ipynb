{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/proteus21/DATA-SCIENCE-STUDY/blob/main/Computer%20Vision/Computer_vision_exercises_part_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision - OpenCV - 10th Task\n",
        "\n",
        "\n",
        "\n",
        "@author Tomasz Skrzypczyk\n",
        "\n",
        "Solved by Bogusław Konefał"
      ],
      "metadata": {
        "id": "KYt0CXJfT4Oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use GPU for this exercise!!!"
      ],
      "metadata": {
        "id": "aVHubMh3Q3Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import collections\n",
        "from six.moves import urllib\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "tf.keras.utils.set_random_seed(1234)\n",
        "random.seed(10)\n"
      ],
      "metadata": {
        "id": "eyVlSg2eUI31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The flowers dataset\n",
        "\n",
        "The flowers dataset consists of images of flowers with 5 possible class labels.\n",
        "\n",
        "When training a machine learning model, we split our data into training and test datasets. We will train the model on our training data and then evaluate how well the model performs on data it has never seen - the test set.\n",
        "\n",
        "Let's download our training and test examples (it may take a while) and split them into train and test sets.\n",
        "\n",
        "Run the following three cells:"
      ],
      "metadata": {
        "id": "b5f-DQaUjEO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the data"
      ],
      "metadata": {
        "id": "CkyQ5WBrWoLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just run this cell\n",
        "FLOWERS_DIR = './flower_photos'\n",
        "TRAIN_FRACTION = 0.8\n",
        "RANDOM_SEED = 2018\n",
        "\n",
        "\n",
        "def download_images():\n",
        "  \"\"\"If the images aren't already downloaded, save them to FLOWERS_DIR.\"\"\"\n",
        "  if not os.path.exists(FLOWERS_DIR):\n",
        "    DOWNLOAD_URL = 'http://download.tensorflow.org/example_images/flower_photos.tgz'\n",
        "    print('Downloading flower images from %s...' % DOWNLOAD_URL)\n",
        "    urllib.request.urlretrieve(DOWNLOAD_URL, 'flower_photos.tgz')\n",
        "    !tar xfz flower_photos.tgz\n",
        "  print('Flower photos are located in %s' % FLOWERS_DIR)\n",
        "\n",
        "\n",
        "def make_train_and_test_sets():\n",
        "  \"\"\"Split the data into train and test sets and get the label classes.\"\"\"\n",
        "  train_examples, val_examples, test_examples = [], [], []\n",
        "  shuffler = random.Random(RANDOM_SEED)\n",
        "  is_root = True\n",
        "  for (dirname, subdirs, filenames) in os.walk(FLOWERS_DIR):\n",
        "    # The root directory gives us the classes\n",
        "    if is_root:\n",
        "      subdirs = sorted(subdirs)\n",
        "      classes = collections.OrderedDict(enumerate(subdirs))\n",
        "      label_to_class = dict([(x, i) for i, x in enumerate(subdirs)])\n",
        "      is_root = False\n",
        "    # The sub directories give us the image files for training.\n",
        "    else:\n",
        "      filenames.sort()\n",
        "      shuffler.shuffle(filenames)\n",
        "      full_filenames = [os.path.join(dirname, f) for f in filenames]\n",
        "      label = dirname.split('/')[-1]\n",
        "      label_class = label_to_class[label]\n",
        "      # An example is the image file and it's label class.\n",
        "      examples = list(zip(full_filenames, [label_class] * len(filenames)))\n",
        "      num_train = int(len(filenames) * TRAIN_FRACTION)\n",
        "      num_valid = int((len(filenames) - num_train)/2)\n",
        "      train_examples.extend(examples[:num_train])\n",
        "      test_examples.extend(examples[num_train:num_train + num_valid])\n",
        "      val_examples.extend(examples[num_train + num_valid:])\n",
        "\n",
        "  shuffler.shuffle(train_examples)\n",
        "  shuffler.shuffle(test_examples)\n",
        "  return train_examples,val_examples, test_examples, classes"
      ],
      "metadata": {
        "id": "7n2MYgLkfubT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the images and split the images into train and test sets.\n",
        "download_images()\n",
        "TRAIN_EXAMPLES, VAL_EXAMPLES, TEST_EXAMPLES, CLASSES = make_train_and_test_sets()\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "\n",
        "print('\\nThe dataset has %d label classes: %s' % (NUM_CLASSES, CLASSES.values()))\n",
        "print('There are %d training images' % len(TRAIN_EXAMPLES))\n",
        "print('there are %d validation images' % len(VAL_EXAMPLES))\n",
        "print('there are %d test images' % len(TEST_EXAMPLES))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp3kn7kzhVm1",
        "outputId": "fb6564af-d29c-4d3b-8d80-65bb36b657bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading flower images from http://download.tensorflow.org/example_images/flower_photos.tgz...\n",
            "Flower photos are located in ./flower_photos\n",
            "\n",
            "The dataset has 5 label classes: odict_values(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'])\n",
            "There are 2934 training images\n",
            "there are 369 validation images\n",
            "there are 367 test images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = [(cv2.resize(cv2.imread(path), (224,224))/255, label) for path, label in TRAIN_EXAMPLES]\n",
        "val_ds = [(cv2.resize(cv2.imread(path), (224,224))/255, label) for path, label in VAL_EXAMPLES]\n",
        "test_ds =  [(cv2.resize(cv2.imread(path), (224,224))/255, label) for path, label in TEST_EXAMPLES]\n",
        "\n",
        "def get_generator(ds):\n",
        "  def data_generator():\n",
        "    for i in range(len(ds)):\n",
        "      yield ds[i][0], (ds[i][1],)\n",
        "  return data_generator\n",
        "\n",
        "train_ds = tf.data.Dataset.from_generator(get_generator(train_ds), output_types=(tf.float32, tf.uint8), output_shapes=((224,224,3),(1,)))\n",
        "train_ds = train_ds.shuffle(100)\n",
        "train_ds = train_ds.batch(64)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_generator(get_generator(val_ds), output_types=(tf.float32, tf.uint8), output_shapes=((224,224,3),(1,)))\n",
        "val_ds = val_ds.batch(64)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_generator(get_generator(test_ds), output_types=(tf.float32, tf.uint8), output_shapes=((224,224,3),(1,)))\n",
        "test_ds = test_ds.batch(64)"
      ],
      "metadata": {
        "id": "w4TLMrBaiSkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple model"
      ],
      "metadata": {
        "id": "0IXYFBvbOa3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we have a simple CNN networkwith no normalization added. Try to train it and remember the test accuracy."
      ],
      "metadata": {
        "id": "rEp2oobXOlwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = [224, 224,3]),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Dropout(0.3),\n",
        "     tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(100, activation='relu'),\n",
        "     tf.keras.layers.Dense(5, activation ='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "YfExvjD1Oc2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7-vO2RHWOvyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "model.fit(train_ds, validation_data=val_ds, epochs = 15, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u0EnrFDO7kH",
        "outputId": "b9a53e4a-80af-4249-9803-eb42e7fa62c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "46/46 [==============================] - 10s 179ms/step - loss: 1.9871 - accuracy: 0.3190 - val_loss: 1.3503 - val_accuracy: 0.3767\n",
            "Epoch 2/15\n",
            "46/46 [==============================] - 8s 170ms/step - loss: 1.1681 - accuracy: 0.5068 - val_loss: 1.1275 - val_accuracy: 0.5393\n",
            "Epoch 3/15\n",
            "46/46 [==============================] - 8s 168ms/step - loss: 1.0596 - accuracy: 0.5781 - val_loss: 1.1227 - val_accuracy: 0.5122\n",
            "Epoch 4/15\n",
            "46/46 [==============================] - 8s 168ms/step - loss: 0.9688 - accuracy: 0.6176 - val_loss: 1.0970 - val_accuracy: 0.5583\n",
            "Epoch 5/15\n",
            "46/46 [==============================] - 8s 171ms/step - loss: 0.9172 - accuracy: 0.6411 - val_loss: 1.0482 - val_accuracy: 0.5935\n",
            "Epoch 6/15\n",
            "46/46 [==============================] - 8s 170ms/step - loss: 0.8430 - accuracy: 0.6776 - val_loss: 1.0667 - val_accuracy: 0.5772\n",
            "Epoch 7/15\n",
            "46/46 [==============================] - 8s 163ms/step - loss: 0.7652 - accuracy: 0.7178 - val_loss: 1.1388 - val_accuracy: 0.5501\n",
            "Epoch 8/15\n",
            "46/46 [==============================] - 8s 170ms/step - loss: 0.6362 - accuracy: 0.7648 - val_loss: 1.2176 - val_accuracy: 0.5583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa60025a160>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = model.evaluate(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CCMN_7HSJET",
        "outputId": "1cd08c6b-75dd-4a62-fc54-3e17f43253a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 1s 105ms/step - loss: 1.0488 - accuracy: 0.6131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Your accuracy: {evaluation_results[1]*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTMB3T6QT0xm",
        "outputId": "af720982-6cc9-477a-e1cd-49532619dabe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your accuracy: 61.30790114402771%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Norm"
      ],
      "metadata": {
        "id": "vhxfPCHfbiw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will see now if adding **BatchNormalization** and/or **Dropout** will help with accuracy score here."
      ],
      "metadata": {
        "id": "2BNVhmHlTtpX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Taks 1:\n",
        "# Add a BatchNormalization layer after each Convolution layer. Each layer that you may need in the future you may find in tf.keras.layers module.\n",
        "model = tf.keras.models.Sequential([\n",
        "     tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = [224, 224,3]),\n",
        "     tf.keras.layers.BatchNormalization(  axis=-1,\n",
        "    momentum=0.99,\n",
        "    epsilon=0.001,\n",
        "    center=True,\n",
        "    scale=True,\n",
        "    beta_initializer='zeros',\n",
        "    gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros',\n",
        "    moving_variance_initializer='ones'),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.BatchNormalization(  axis=-1,\n",
        "    momentum=0.99,\n",
        "    epsilon=0.001,\n",
        "    center=True,\n",
        "    scale=True,\n",
        "    beta_initializer='zeros',\n",
        "    gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros',\n",
        "    moving_variance_initializer='ones'),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Dropout(0.5),\n",
        "     tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.BatchNormalization(  axis=-1,\n",
        "    momentum=0.99,\n",
        "    epsilon=0.001,\n",
        "    center=True,\n",
        "    scale=True,\n",
        "    beta_initializer='zeros',\n",
        "    gamma_initializer='ones',\n",
        "    moving_mean_initializer='zeros',\n",
        "    moving_variance_initializer='ones'),\n",
        "    tf.keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(100, activation='relu'),\n",
        "     tf.keras.layers.Dense(5, activation ='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "9C7lwbb_SK2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "WNzwem6XZxFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)\n",
        "model.fit(train_ds, validation_data=val_ds, epochs = 15, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Y9wJheZ2Nz",
        "outputId": "7656cc7a-9053-4b61-979a-0f48f9e52ca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "46/46 [==============================] - 15s 250ms/step - loss: 9.8560 - accuracy: 0.2110 - val_loss: 1.6098 - val_accuracy: 0.1734\n",
            "Epoch 2/15\n",
            "46/46 [==============================] - 11s 241ms/step - loss: 1.6094 - accuracy: 0.2076 - val_loss: 1.6088 - val_accuracy: 0.2439\n",
            "Epoch 3/15\n",
            "46/46 [==============================] - 11s 235ms/step - loss: 1.6083 - accuracy: 0.2447 - val_loss: 1.6089 - val_accuracy: 0.2412\n",
            "Epoch 4/15\n",
            "46/46 [==============================] - 11s 241ms/step - loss: 1.6072 - accuracy: 0.2447 - val_loss: 1.6101 - val_accuracy: 0.2412\n",
            "Epoch 5/15\n",
            "46/46 [==============================] - 11s 237ms/step - loss: 1.6061 - accuracy: 0.2447 - val_loss: 1.6101 - val_accuracy: 0.2602\n",
            "Epoch 6/15\n",
            "46/46 [==============================] - 11s 234ms/step - loss: 1.6050 - accuracy: 0.2447 - val_loss: 1.6104 - val_accuracy: 0.2575\n",
            "Epoch 7/15\n",
            "46/46 [==============================] - 11s 238ms/step - loss: 1.6042 - accuracy: 0.2447 - val_loss: 1.6098 - val_accuracy: 0.2493\n",
            "Epoch 8/15\n",
            "46/46 [==============================] - 11s 236ms/step - loss: 1.6034 - accuracy: 0.2447 - val_loss: 1.6064 - val_accuracy: 0.2493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6188afb80>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = model.evaluate(test_ds)\n",
        "print(f\"Your accuracy: {evaluation_results[1]*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bSOdrt8bdTY",
        "outputId": "94bd1999-5bdd-4d5c-aad2-91a3c0ec3d74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 59ms/step - loss: 2.7214 - accuracy: 0.2643\n",
            "Your accuracy: 26.430517435073853%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Batch Norm should have helped in increasing the model's results by 1-3 %."
      ],
      "metadata": {
        "id": "5Oe897PVdG11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout"
      ],
      "metadata": {
        "id": "7ayuuKtIbZUf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giVO-ZPAbaQ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}